{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Yoann\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras import layers, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import Model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import PReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import add\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the data is too large to fit in memory, we will use a generator to load the data in batches.\n",
    "def load_image(path):\n",
    "    try:\n",
    "        img = cv2.imread(path)\n",
    "        # If the image has not 3 channels, generate a 3 channels image from the gray scale image\n",
    "        if img.shape[2]!=3:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        return img\n",
    "    except:\n",
    "        print(path)\n",
    "        return None\n",
    "\n",
    "def load_data(batch_images, data_augmentation=0):\n",
    "    imgs_hr, imgs_lr = np.empty((0, 1080, 1920, 3)), np.empty((0, 270, 480, 3))\n",
    "    for img_path in batch_images:\n",
    "        img_hr = load_image(img_path)\n",
    "        # If the image is not at 1920x1080, resize it to 1920x1080\n",
    "        if img_hr.shape[0]!=1080 or img_hr.shape[1]!=1920:\n",
    "            img_hr = cv2.resize(img_hr, (1920, 1080), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # Make data augmentation here\n",
    "        if data_augmentation>0:\n",
    "            img_hr = aug_image(img_hr, data_augmentation)\n",
    "        img_lr = cv2.resize(img_hr, (480, 270), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        imgs_hr = np.append(imgs_hr, [img_hr], axis=0)\n",
    "        imgs_lr = np.append(imgs_lr, [img_lr], axis=0)\n",
    "    return imgs_hr, imgs_lr\n",
    "\n",
    "# Augment the image by applying random rotation, random zoom and random translation\n",
    "def aug_image(img,num_of_aug):\n",
    "    img_list = []\n",
    "    for i in range(num_of_aug):\n",
    "        # Random rotation\n",
    "        angle = np.random.randint(0,360)\n",
    "        img_rot = rotate_image(img, angle)\n",
    "        # Random zoom\n",
    "        zoom_factor = np.random.randint(1,5)\n",
    "        img_zoom = zoom_image(img_rot, zoom_factor)\n",
    "        # Random translation\n",
    "        x_shift = np.random.randint(-50,50)\n",
    "        y_shift = np.random.randint(-50,50)\n",
    "        img_shift = shift_image(img_zoom, x_shift, y_shift)\n",
    "        img_list.append(img_shift)\n",
    "    return img_list[np.random.randint(0,num_of_aug)]\n",
    "\n",
    "\n",
    "def rotate_image(img, angle):\n",
    "    rows,cols = img.shape[0:2]\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),angle,1)\n",
    "    img_rot = cv2.warpAffine(img,M,(cols,rows))\n",
    "    return img_rot\n",
    "\n",
    "def zoom_image(img, zoom_factor):\n",
    "    rows,cols = img.shape[0:2]\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),0,zoom_factor)\n",
    "    img_zoom = cv2.warpAffine(img,M,(cols,rows))\n",
    "    return img_zoom\n",
    "\n",
    "def shift_image(img, x_shift, y_shift):\n",
    "    rows,cols = img.shape[0:2]\n",
    "    M = np.float32([[1,0,x_shift],[0,1,y_shift]])\n",
    "    img_shift = cv2.warpAffine(img,M,(cols,rows))\n",
    "    return img_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Add, Lambda\n",
    "from tensorflow.python.keras.layers import PReLU\n",
    "\n",
    "from utils.normalization import normalize_01, denormalize_m11\n",
    "\n",
    "\n",
    "upsamples_per_scale = {\n",
    "    2: 1,\n",
    "    4: 2,\n",
    "    8: 3\n",
    "}\n",
    "\n",
    "\n",
    "def pixel_shuffle(scale):\n",
    "    return lambda x: tf.nn.depth_to_space(x, scale)\n",
    "\n",
    "\n",
    "def upsample(x_in, num_filters):\n",
    "    x = Conv2D(num_filters, kernel_size=3, padding='same')(x_in)\n",
    "    x = Lambda(pixel_shuffle(scale=2))(x)\n",
    "    return PReLU(shared_axes=[1, 2])(x)\n",
    "\n",
    "\n",
    "def residual_block(block_input, num_filters, momentum=0.8):\n",
    "    x = Conv2D(num_filters, kernel_size=3, padding='same')(block_input)\n",
    "    x = BatchNormalization(momentum=momentum)(x)\n",
    "    x = PReLU(shared_axes=[1, 2])(x)\n",
    "    x = Conv2D(num_filters, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization(momentum=momentum)(x)\n",
    "    x = Add()([block_input, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_srresnet(scale=4, num_filters=64, num_res_blocks=16):\n",
    "    if scale not in upsamples_per_scale:\n",
    "        raise ValueError(f\"available scales are: {upsamples_per_scale.keys()}\")\n",
    "\n",
    "    num_upsamples = upsamples_per_scale[scale]\n",
    "\n",
    "    lr = Input(shape=(None, None, 3))\n",
    "    x = Lambda(normalize_01)(lr)\n",
    "\n",
    "    x = Conv2D(num_filters, kernel_size=9, padding='same')(x)\n",
    "    x = x_1 = PReLU(shared_axes=[1, 2])(x)\n",
    "\n",
    "    for _ in range(num_res_blocks):\n",
    "        x = residual_block(x, num_filters)\n",
    "\n",
    "    x = Conv2D(num_filters, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x_1, x])\n",
    "\n",
    "    for _ in range(num_upsamples):\n",
    "        x = upsample(x, num_filters * 4)\n",
    "\n",
    "    x = Conv2D(3, kernel_size=9, padding='same', activation='tanh')(x)\n",
    "    sr = Lambda(denormalize_m11)(x)\n",
    "\n",
    "    return Model(lr, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Add, Lambda, LeakyReLU, Flatten, Dense\n",
    "from tensorflow.python.keras.layers import PReLU\n",
    "\n",
    "from utils.normalization import normalize_m11\n",
    "\n",
    "\n",
    "def discriminator_block(x_in, num_filters, strides=1, batchnorm=True, momentum=0.8):\n",
    "    x = Conv2D(num_filters, kernel_size=3, strides=strides, padding='same')(x_in)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization(momentum=momentum)(x)\n",
    "    return LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "\n",
    "def build_discriminator(hr_crop_size):\n",
    "    x_in = Input(shape=(hr_crop_size, hr_crop_size, 3))\n",
    "    x = Lambda(normalize_m11)(x_in)\n",
    "\n",
    "    x = discriminator_block(x, 64, batchnorm=False)\n",
    "    x = discriminator_block(x, 64, strides=2)\n",
    "\n",
    "    x = discriminator_block(x, 128)\n",
    "    x = discriminator_block(x, 128, strides=2)\n",
    "\n",
    "    x = discriminator_block(x, 256)\n",
    "    x = discriminator_block(x, 256, strides=2)\n",
    "\n",
    "    x = discriminator_block(x, 512)\n",
    "    x = discriminator_block(x, 512, strides=2)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(1024)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(x_in, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset_mappings import random_crop, random_flip, random_rotate, random_lr_jpeg_noise\n",
    "from utils.metrics import psnr_metric\n",
    "from utils.config import config\n",
    "from utils.callbacks import SaveCustomCheckpoint\n",
    "from tensorflow.python.data.experimental import AUTOTUNE\n",
    "\n",
    "\n",
    "hr_crop_size = 96\n",
    "\n",
    "train_mappings = [\n",
    "    lambda lr, hr: random_crop(lr, hr, hr_crop_size=hr_crop_size, scale=4), \n",
    "    random_flip, \n",
    "    random_rotate, \n",
    "    random_lr_jpeg_noise]\n",
    "\n",
    "def data_loader_train(paths, batch_size, mappings,nb_batches=10):\n",
    "    batch_images_hr, batch_images_lr = [], []\n",
    "    for i in range(nb_batches):\n",
    "        batch_paths= np.random.choice(a=paths, size=batch_size)\n",
    "        images_hr, images_lr = load_data(batch_paths, data_augmentation=0)\n",
    "        batch_images_hr.append(images_hr)\n",
    "        batch_images_lr.append(images_lr)\n",
    "        del images_hr, images_lr, batch_paths\n",
    "\n",
    "    # Convert the list into tf dataset\n",
    "    batch_images_lr = np.concatenate(batch_images_lr, axis=0)\n",
    "    batch_images_hr = np.concatenate(batch_images_hr, axis=0)\n",
    "    batch_images_lr = tf.data.Dataset.from_tensor_slices(batch_images_lr)\n",
    "    batch_images_hr = tf.data.Dataset.from_tensor_slices(batch_images_hr)\n",
    "\n",
    "    dataset = tf.data.Dataset.zip((batch_images_lr, batch_images_hr))\n",
    "    del batch_images_lr, batch_images_hr\n",
    "    for mapping in mappings:\n",
    "        dataset = dataset.map(mapping,num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_path = './data/test'\n",
    "train_set_path = []\n",
    "for path in os.listdir(train_path):\n",
    "    train_set_path.append(os.path.join(train_path, path))\n",
    "\n",
    "train_dataset = data_loader_train(paths=train_set_path, batch_size=10, mappings=train_mappings)\n",
    "valid_dataset_subset = train_dataset.take(4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-1, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.cardinality())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "valid_dataset_subset = train_dataset.take(10)\n",
    "\n",
    "\n",
    "generator = build_srresnet(scale=4, num_filters=64, num_res_blocks=16)\n",
    "\n",
    "checkpoint_dir=f'./ckpt/sr_resnet'\n",
    "\n",
    "learning_rate=1e-4\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(0),\n",
    "                                 epoch=tf.Variable(0),\n",
    "                                 psnr=tf.Variable(0.0),\n",
    "                                 optimizer=Adam(learning_rate),\n",
    "                                 model=generator)\n",
    "\n",
    "checkpoint_manager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
    "                                                directory=checkpoint_dir,\n",
    "                                                max_to_keep=3)\n",
    "\n",
    "if checkpoint_manager.latest_checkpoint:\n",
    "    checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
    "    print(f'Model restored from checkpoint at step {checkpoint.step.numpy()} with validation PSNR {checkpoint.psnr.numpy()}.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy, MeanAbsoluteError\n",
    "\n",
    "training_steps = 1_000_000\n",
    "\n",
    "steps_per_epoch = 1000\n",
    "\n",
    "training_epochs = training_steps / steps_per_epoch\n",
    "loss_for_plot = []\n",
    "\n",
    "\n",
    "if checkpoint.epoch.numpy() < training_epochs:\n",
    "    remaining_epochs = int(training_epochs - checkpoint.epoch.numpy())\n",
    "    print(f\"Continuing Training from epoch {checkpoint.epoch.numpy()}. Remaining epochs: {remaining_epochs}.\")\n",
    "    save_checkpoint_callback = SaveCustomCheckpoint(checkpoint_manager, steps_per_epoch)\n",
    "    checkpoint.model.compile(optimizer=checkpoint.optimizer, loss=MeanSquaredError(), metrics=[psnr_metric])\n",
    "    checkpoint.model.fit(train_dataset,validation_data=valid_dataset_subset, steps_per_epoch=steps_per_epoch, epochs=remaining_epochs, callbacks=[save_checkpoint_callback])\n",
    "    # Compute the loss on the validation set\n",
    "    loss = checkpoint.model.evaluate(valid_dataset_subset, steps=1)\n",
    "    loss_for_plot.append(loss)\n",
    "else:\n",
    "    print(\"Training already completed. To continue training, increase the number of training steps\")\n",
    "\n",
    "weights_directory = f\"weights/srresnet\"\n",
    "os.makedirs(weights_directory, exist_ok=True)\n",
    "weights_file = f'{weights_directory}/generator.h5'\n",
    "checkpoint.model.save_weights(weights_file)\n",
    "\n",
    "# Save the loss for each epoch in a csv file\n",
    "loss_df = pd.DataFrame(loss_for_plot)\n",
    "loss_df.to_csv(f'{weights_directory}/loss.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_directory = f\"weights/srresnet\"\n",
    "os.makedirs(weights_directory, exist_ok=True)\n",
    "weights_file = f'{weights_directory}/generator.h5'\n",
    "checkpoint.model.save_weights(weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_srresnet(scale=4)\n",
    "generator.load_weights(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator(hr_crop_size=hr_crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "layer_5_4 = 20\n",
    "vgg = VGG19(input_shape=(None, None, 3), include_top=False)\n",
    "perceptual_model = Model(vgg.input, vgg.layers[layer_5_4].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_entropy = BinaryCrossentropy()\n",
    "mean_squared_error = MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "learning_rate=PiecewiseConstantDecay(boundaries=[100000], values=[1e-4, 1e-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = Adam(learning_rate=learning_rate)\n",
    "discriminator_optimizer = Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srgan_checkpoint_dir=f'./ckpt/srgan'\n",
    "\n",
    "srgan_checkpoint = tf.train.Checkpoint(step=tf.Variable(0),\n",
    "                                       psnr=tf.Variable(0.0),\n",
    "                                       generator_optimizer=Adam(learning_rate),\n",
    "                                       discriminator_optimizer=Adam(learning_rate),\n",
    "                                       generator=generator,\n",
    "                                       discriminator=discriminator)\n",
    "\n",
    "srgan_checkpoint_manager = tf.train.CheckpointManager(checkpoint=srgan_checkpoint,\n",
    "                                                directory=srgan_checkpoint_dir,\n",
    "                                                max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if srgan_checkpoint_manager.latest_checkpoint:\n",
    "    srgan_checkpoint.restore(srgan_checkpoint_manager.latest_checkpoint)\n",
    "    print(f'Model restored from checkpoint at step {srgan_checkpoint.step.numpy()} with validation PSNR {srgan_checkpoint.psnr.numpy()}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(lr, hr):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        lr = tf.cast(lr, tf.float32)\n",
    "        hr = tf.cast(hr, tf.float32)\n",
    "\n",
    "        sr = srgan_checkpoint.generator(lr, training=True)\n",
    "\n",
    "        hr_output = srgan_checkpoint.discriminator(hr, training=True)\n",
    "        sr_output = srgan_checkpoint.discriminator(sr, training=True)\n",
    "\n",
    "        con_loss = calculate_content_loss(hr, sr)\n",
    "        gen_loss = calculate_generator_loss(sr_output)\n",
    "        perc_loss = con_loss + 0.001 * gen_loss\n",
    "        disc_loss = calculate_discriminator_loss(hr_output, sr_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(perc_loss, srgan_checkpoint.generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, srgan_checkpoint.discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, srgan_checkpoint.generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, srgan_checkpoint.discriminator.trainable_variables))\n",
    "\n",
    "    return perc_loss, disc_loss\n",
    "\n",
    "@tf.function\n",
    "def calculate_content_loss(hr, sr):\n",
    "    sr = preprocess_input(sr)\n",
    "    hr = preprocess_input(hr)\n",
    "    sr_features = perceptual_model(sr) / 12.75\n",
    "    hr_features = perceptual_model(hr) / 12.75\n",
    "    return mean_squared_error(hr_features, sr_features)\n",
    "\n",
    "def calculate_generator_loss(sr_out):\n",
    "    return binary_cross_entropy(tf.ones_like(sr_out), sr_out)\n",
    "\n",
    "def calculate_discriminator_loss(hr_out, sr_out):\n",
    "    hr_loss = binary_cross_entropy(tf.ones_like(hr_out), hr_out)\n",
    "    sr_loss = binary_cross_entropy(tf.zeros_like(sr_out), sr_out)\n",
    "    return hr_loss + sr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Mean\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "perceptual_loss_metric = Mean()\n",
    "discriminator_loss_metric = Mean()\n",
    "\n",
    "step = srgan_checkpoint.step.numpy()\n",
    "steps = 200000\n",
    "\n",
    "monitor_folder = f\"monitor_training/srgan\"\n",
    "os.makedirs(monitor_folder, exist_ok=True)\n",
    "\n",
    "now = time.perf_counter()\n",
    "\n",
    "loss_for_plot = []\n",
    "\n",
    "for lr, hr in train_dataset.take(steps - step):\n",
    "    srgan_checkpoint.step.assign_add(1)\n",
    "    step = srgan_checkpoint.step.numpy()\n",
    "\n",
    "    perceptual_loss, discriminator_loss = train_step(lr, hr)\n",
    "    perceptual_loss_metric(perceptual_loss)\n",
    "    discriminator_loss_metric(discriminator_loss)\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        psnr_values = []\n",
    "        loss_array = []\n",
    "        for lr, hr in valid_dataset_subset:\n",
    "            sr = srgan_checkpoint.generator.predict(lr)[0]\n",
    "            sr = tf.clip_by_value(sr, 0, 255)\n",
    "            sr = tf.round(sr)\n",
    "            sr = tf.cast(sr, tf.uint8)\n",
    "\n",
    "            loss_array.append(srgan_checkpoint.generator.evaluate(lr, hr, steps=1))\n",
    "\n",
    "            psnr_value = psnr_metric(hr, sr)[0]\n",
    "            psnr_values.append(psnr_value)\n",
    "            psnr = tf.reduce_mean(psnr_values)\n",
    "\n",
    "\n",
    "        mean_loss = np.mean(loss_array, axis=0)\n",
    "        image = Image.fromarray(sr.numpy())\n",
    "        image.save(f\"{monitor_folder}/{step}.png\" )\n",
    "        \n",
    "        duration = time.perf_counter() - now\n",
    "        \n",
    "        now = time.perf_counter()\n",
    "\n",
    "        loss_for_plot.append([step, perceptual_loss_metric.result().numpy(), discriminator_loss_metric.result().numpy(), psnr.numpy(),mean_loss])\n",
    "        \n",
    "        print(f'{step}/{steps}, psnr = {psnr}, perceptual loss = {perceptual_loss_metric.result():.4f}, discriminator loss = {discriminator_loss_metric.result():.4f} ({duration:.2f}s)')\n",
    "        \n",
    "        perceptual_loss_metric.reset_states()\n",
    "        discriminator_loss_metric.reset_states()\n",
    "        \n",
    "        srgan_checkpoint.psnr.assign(psnr)\n",
    "        srgan_checkpoint_manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_directory = f\"weights/srgan\"\n",
    "os.makedirs(weights_directory, exist_ok=True)\n",
    "weights_file = f'{weights_directory}/generator.h5'\n",
    "srgan_checkpoint.generator.save_weights(weights_file)\n",
    "# Save the loss for each epoch in a csv file\n",
    "loss_df = pd.DataFrame(loss_for_plot)\n",
    "loss_df.to_csv(f'{weights_directory}/loss.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
